## 📘 [AI] 위클리페이퍼 \#13

> **작성일**: 2025년 11월 10일
> **작성자**: 이유노

## 🔹 01. LangChain을 사용해 RAG 시스템을 구축할 때 어떤 주요 구성 요소들이 필요하고, 각각 어떤 역할을 하나요?

RAG(Retrieval-Augmented Generation) 시스템은 LLM의 지식을 외부 문서로 '보강(Augment)'하여 답변을 생성하는 아키텍처입니다. LangChain은 이 과정을 모듈화하여 쉽게 구현할 수 있도록 돕습니다.

### 📌 RAG의 2단계 핵심 프로세스

1.  **인덱싱 (Indexing):** 외부 문서를 LLM이 참조할 수 있도록 준비하는 **오프라인 과정**입니다.
2.  **검색 및 생성 (Retrieval & Generation):** 사용자 질문이 들어왔을 때, 관련 문서를 찾고(Retrieve) LLM이 이를 참조해 답변을 생성(Generate)하는 **온라인 과정**입니다.

-----

### 📌 1. 인덱싱(Indexing) 주요 구성 요소

| 구성 요소 | 역할 |
| :--- | :--- |
| **Document Loaders** | `PDF`, `TXT`, 웹페이지, DB 등 다양한 소스로부터 문서를 로드합니다. |
| **Text Splitters** | 로드된 문서를 LLM이 처리하기 좋은 작은 단위(Chunk)로 분할합니다. |
| **Embeddings** | 분할된 텍스트 청크를 의미를 파악할 수 있는 숫자 벡터(Vector)로 변환합니다. |
| **Vector Stores** | 임베딩된 벡터를 저장하고, 유사도 검색을 통해 빠르게 관련 문서를 찾을 수 있도록 돕는 DB입니다. (예: FAISS, Chroma) |

-----

### 📌 2. 검색 및 생성(Retrieval & Generation) 주요 구성 요소

| 구성 요소 | 역할 |
| :--- | :--- |
| **Retriever** | 사용자의 질문(Query)을 임베딩하고, Vector Store에서 가장 유사도가 높은 관련 문서 청크를 검색(Retrieve)합니다. |
| **Prompt** | LLM에게 제공할 프롬프트를 구성합니다. "다음 문서를 참조하여 질문에 답해 줘. 문서: {context}, 질문: {question}"과 같은 템플릿입니다. |
| **LLM (Chat Model)** | Retriever가 찾은 참조 문서(Context)와 원본 질문(Question)이 포함된 프롬프트를 받아, 최종 답변을 생성(Generate)합니다. |
| **Chain (LCEL)** | 위의 모든 구성 요소(Retriever, Prompt, LLM)를 `|` (파이프) 기호 등으로 연결하여 RAG 파이프라인을 완성하고 실행합니다. |

-----

## 🔹 02. RAG 시스템의 성능을 평가하는 방법에는 어떤 것들이 있고, 독립 평가와 종단간 평가의 차이는 무엇인가요?

RAG 시스템은 '검색'과 '생성'이라는 두 가지 핵심 기능이 결합되어 있어, 평가 역시 두 가지 관점에서 접근해야 합니다.

### 📌 1. 독립/구성 요소 평가 (Atomic / Component-Level Evaluation)

> RAG 파이프라인의 **개별 부품(Retriever, Generator)** 이 제 역할을 잘 수행하는지 독립적으로 평가합니다. 시스템에 문제가 생겼을 때 **어디가 원인인지(Debugging)** 파악하는 데 유용합니다.

  * **Retriever 평가 (검색 성능):**

      * **Context Precision (정확성):** 검색된 문서 청크가 질문과 **얼마나 관련성이 높은가?**
      * **Context Recall (재현율):** 질문에 답하기 위해 필요한 **모든** 관련 문서를 빠뜨리지 않고 잘 가져왔는가?

  * **Generator 평가 (생성 성능):**

      * **Faithfulness (충실성):** LLM이 생성한 답변이 검색된 **문서(Context)의 내용에만 기반**했는가? (환각/Hallucination이 없는가?)
      * **Answer Relevancy (답변 관련성):** 생성된 답변이 **원본 질문**의 의도에 부합하는가?

-----

### 📌 2. 종단간 평가 (End-to-End Evaluation)

> 시스템 전체를 **하나의 블랙박스**로 보고, 사용자 관점에서 **"최종 답변"** 이 얼마나 만족스러운지만 평가합니다. 시스템이 실제 사용자에게 제공될 때의 품질을 측정합니다.

  * **Answer Correctness (답변 정확성):** 최종 답변이 (미리 준비된 정답과 비교했을 때) 사실적으로 올바른가?
  * **Citation Accuracy (인용 정확성):** 답변의 근거로 제시된 출처(인용)가 정확하고 관련성이 높은가?

-----

### 📌 평가 방식의 차이점

> **종단간 평가(End-to-End)** 는 "답변이 틀렸어" (문제 현상)를 알려줍니다.
> **독립 평가(Atomic)** 는 "Retriever가 관련 없는 문서를 가져왔어" 또는 "Generator가 문서를 무시하고 환각을 일으켰어" (문제 원인)를 알려줍니다.

-----

## 🔹 03. RAG 시스템에서 'Agent'는 어떤 개념인지, 어떻게 구현할 수 있는지 정리해보세요.

### 📌 Agent의 개념 (Agentic RAG)

표준 RAG 시스템은 `검색 -> 생성`의 2단계 고정 파이프라인을 따릅니다. 반면 **'Agent'** 는 LLM을 **'생각하는 뇌'** 로 사용하여, 주어진 작업을 **스스로 계획하고, 도구를 선택하며, 동적으로 실행**하는 주체입니다.

**Agentic RAG**는 이 Agent에게 'RAG'를 하나의 '도구(Tool)'로 쥐여주는 개념입니다.

  * Agent는 사용자의 질문을 받고 **스스로 판단**합니다.
  * "이 질문은 내 지식으로 답할 수 있으니 그냥 답해야지."
  * "이 질문은 외부 정보가 필요하군. **'RAG 검색 도구'** 를 사용해야겠다."
  * "이 질문은 RAG 도구뿐만 아니라 **'웹 검색 도구'** 도 함께 사용해서 종합해야겠다."

-----

### 📌 표준 RAG vs Agentic RAG

| 구분 | 표준 RAG (Chain) | Agentic RAG (Agent) |
| :--- | :--- | :--- |
| **흐름** | 고정된 파이프라인 (Retrieve → Generate) | 동적 워크플로우 (Reasoning → Tool Use → ...) |
| **결정** | 사람이 미리 설계한 순서대로만 작동 | LLM(Agent)이 상황에 맞게 도구 사용 여부 결정 |
| **유연성** | 낮음 (정해진 작업만 수행) | 높음 (RAG, 웹 검색, DB 조회 등 여러 도구 조합 가능) |
| **예시** | "문서"에 대해서만 질문 답변 | "A 문서의 내용을 요약하고, 최신 뉴스도 검색해 줘." |

-----

### 📌 LangChain에서의 구현 방법

1.  **도구(Tool) 정의:** 표준 RAG 파이프라인(Retriever + LLM Chain)을 구축한 뒤, 이것을 `Tool` 객체로 감쌉니다.
    ```python
    # 1. 기존 RAG 체인을 만듭니다.
    rag_chain = ... 

    # 2. RAG 체인을 '도구'로 만듭니다.
    rag_tool = Tool(
        name="document_search",
        func=rag_chain.invoke,
        description="사내 문서나 매뉴얼에 대해 질문할 때 유용합니다."
    )
    ```
2.  **Agent 생성:** LLM(판단 주체)과 위에서 만든 `rag_tool` (및 다른 도구들, 예: `DuckDuckGoSearchRun`)을 결합하여 Agent를 생성합니다. (예: `create_openai_tools_agent` 사용)
3.  **Agent 실행:** AgentExecutor가 Agent를 실행합니다. 사용자의 질문을 받은 Agent는 `description`을 보고 `rag_tool`을 호출할지, 다른 도구를 호출할지, 아니면 그냥 답할지 스스로 결정합니다.

-----

> **정리**
> LangChain RAG 시스템은 **문서 로딩, 분할, 임베딩, 저장(인덱싱)** 과 **검색, 생성(RAG 체인)** 으로 구성됩니다.
> 시스템 평가는 **종단간(최종 답변 품질)** 과 **독립적(부품별 성능)** 평가로 나뉘며, 디버깅을 위해 독립 평가가 중요합니다.
> **Agent**는 RAG를 고정된 파이프라인이 아닌, LLM이 스스로 판단하여 사용하는 **'선택 가능한 도구'** 로 만들어 시스템의 유연성을 극대화하는 개념입니다.
