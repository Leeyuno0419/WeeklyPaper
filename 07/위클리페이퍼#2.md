# 📘 [AI] 위클리페이퍼 #2
---
> **작성일**: 2025년 7월 21일  
> **작성자**: 이유노
## 🔹 01. 지도 학습과 비지도 학습의 차이는 무엇일까요?
### 📌 지도 학습 (Supervised Learning)

**정답(label)** 이 있는 데이터를 가지고 학습하는 방법입니다.
- 목표는, 입력 → 정답(label) 관계를 배우는 것.
- 예를 들어, 입력: "이 사진은 고양이인가요, 개인가요?"정답: "고양이"
  
---

### 📌 비지도 학습 (Unsupervised Learning)

**정답(label)** 이 없이, 데이터만 있는 상태에서 패턴이나 구조를 찾는 학습 방법입니다.
- 목표는, 입력 간의 숨겨진 구조를 파악하는 것.
- 예를 들어, 수많은 쇼핑 고객의 구매 데이터를 가지고, "비슷한 취향의 사람끼리 묶기(군집화)"
  
---

### ✅ TIP: 머신러닝 모델을 만들기 전, 지도 학습인지 비지도 학습인지 결정하는법
- "내 데이터에 정답이 있는가?"를 판단
- 정답이 존재 -> 지도 학습
- 정답이 존재하지 않음 -> 비지도 학습

## 🔹 02. 손실 함수(Loss Function)란 무엇이며, 왜 중요한가요?

### 📌 손실 함수(Loss Function)란?

**모델의 예측값과 실제 정답(Label)의 차이를 수치로 나타낸 함수**입니다.

- 손실(Loss)은 예측 하나하나에 대한 오차를 뜻합니다.
- 이 오차를 기반으로 모델이 학습 방향을 결정합니다.
- 모든 데이터의 손실을 평균낸 값을 **비용 함수(Cost Function)** 라고 합니다.
- 예: 컵라면을 익히는 데 적절한 시간 3분 (멀어질 수록 손실 발생)

---

### 📌 왜 중요한가요?

- 손실 함수는 **모델이 무엇을 학습해야 할지 알려주는 나침반 역할**을 합니다.
- 머신러닝 모델은 손실 함수를 **최소화(minimize)** 하도록 매개변수(가중치)를 업데이트합니다.
- 손실이 작을수록 예측이 정확하다는 의미이며, 따라서 **손실 함수는 모델의 학습 성능을 평가하는 핵심 기준**입니다.

---

### 📌 손실 함수와 비용 함수 차이

| 구분 | 설명 |
|------|------|
| 손실 함수 (Loss Function) | 하나의 샘플에 대한 오차를 계산 |
| 비용 함수 (Cost Function) | 전체 데이터에 대한 평균 손실 |

> 즉, Loss는 미세하게 보고, Cost는 전체적으로 보는 관점입니다.

---

### 📌 대표적인 손실 함수 종류

| 문제 유형 | 손실 함수 | 설명 |
|-----------|-----------|------|
| 회귀 | MSE (Mean Squared Error) | 오차의 제곱 평균. 큰 오차에 더 큰 페널티 |
| 회귀 | MAE (Mean Absolute Error) | 오차의 절대값 평균. 이상치에 덜 민감 |
| 분류 | Cross Entropy (교차 엔트로피) | 예측 확률과 실제 클래스 간의 차이를 평가 |

---

### ✅ 한 줄 요약

> 손실 함수는 "모델이 얼마나 틀렸는지" 알려주는 기준, 머신러닝은 이 손실을 줄이기 위해 학습을 반복하는 구조입니다.

## 🔹 03. 모델 학습 시 발생할 수 있는 편향(Bias)과 분산(Variance)에 대해 설명하고, 두 개념의 관계는?

### 📌 편향(Bias)란?

모델이 **데이터의 실제 패턴을 단순화해 잘못 학습**한 정도를 의미합니다.  
쉽게 말해, **모델이 문제를 지나치게 단순하게 이해하는 정도**입니다.

- 일반적으로 **너무 단순한 모델**에서 발생
- 모델이 학습 데이터와 테스트 데이터 **모두에서 성능이 낮음**
- 대표적 현상: **과소적합(Underfitting)**

#### 🧠 예시
- 비선형적인 관계를 **직선(linear)**으로 설명하려고 하면 예측이 늘 틀림
- 선형 회귀로 곡선형 데이터를 예측하려는 경우

---

### 📌 분산(Variance)란?

모델이 학습 데이터에 **너무 민감하게 반응**하는 정도를 의미합니다.  
즉, 학습 데이터에만 너무 최적화되어 **새로운 데이터에선 예측이 불안정**한 상태입니다.

- 일반적으로 **너무 복잡한 모델**에서 발생
- 학습 데이터 성능은 좋지만, 테스트 성능은 나쁨
- 대표적 현상: **과적합(Overfitting)**

#### 🧠 예시
- 다항 회귀에서 차수를 너무 높여서 데이터에 지나치게 맞춘 경우

---

### 📌 편향 vs 분산: 한눈에 비교

| 항목 | 편향(Bias) | 분산(Variance) |
|------|------------|----------------|
| 정의 | 예측값과 실제값 간의 일관된 차이 | 학습 데이터 변화에 따라 예측이 달라지는 정도 |
| 원인 | 모델이 너무 단순할 때 | 모델이 너무 복잡할 때 |
| 영향 | 훈련/테스트 모두 성능 낮음 | 훈련 성능 높고, 테스트 성능 낮음 |
| 대표 문제 | 과소적합(Underfitting) | 과적합(Overfitting) |

---

### 📌 편향-분산 트레이드오프 (Bias-Variance Trade-off)

> **편향과 분산은 서로 반비례 관계**에 있습니다.  
> 하나를 줄이면 다른 하나가 커질 수 있으므로 **두 요소 간의 균형(Balance)**이 중요합니다.

- 너무 단순한 모델 → **편향↑**, 분산↓ → 전체 오류 증가
- 너무 복잡한 모델 → **편향↓**, 분산↑ → 전체 오류 증가
- ✅ **이 둘의 균형점**을 찾아야 **전체 에러(Total Error)**를 최소화할 수 있습니다.

---

### 📌 시각적 비유 (타겟판 예시로 설명)

- **편향 높은 경우**: 한쪽에만 빗나간 화살이 몰려 있음  
- **분산 높은 경우**: 중심은 맞추지만, 흩어져서 정확도가 낮음  
- **둘 다 좋은 경우**: 중심 근처에 고르게 밀집

---

### ✅ 한 줄 요약

> 편향은 모델이 문제를 **단순화해서 못 맞추는 경우**,  
> 분산은 모델이 **데이터에 과하게 적응해서 일반화를 못 하는 경우**입니다.  
> 머신러닝에서 가장 중요한 건 **두 개념 사이의 균형을 맞추는 것**입니다.

## 🔹 04. K-폴드 교차 검증에서 K의 값을 선택할 때 고려해야 할 점은 무엇인가요?

### 📌 K-폴드 교차 검증이란?

전체 데이터를 **K개의 균등한 조각(fold)**으로 나누고,  
각 fold를 **검증용(Validation)**으로 한 번씩 사용하여 **K번 학습과 평가를 반복**하는 검증 방법입니다.

- 모델이 **데이터 분할에 따라 성능이 달라지는 현상(분산)**을 줄여줌
- 데이터가 적을 때도 **효율적으로 성능 평가** 가능

---

### 📌 K 값이 클수록? 작을수록?

| K 값 | 장점 | 단점 |
|------|------|------|
| 작을 때 (예: K=3, 5) | 빠른 계산 속도, 적은 연산량 | 성능 추정이 다소 불안정할 수 있음 |
| 클 때 (예: K=10, K=n) | 더 안정적인 성능 추정, 과적합 위험 감소 | 계산량 증가, 훈련 속도 느림 |

---

### 📌 K 값 선택 시 고려사항

1. **데이터 양**
   - 데이터가 적을수록 K를 크게 설정하는 것이 유리  
   - 예: 데이터가 100개뿐이라면 K=10 (각 fold 10개)로 하면 학습에 90%, 검증에 10% 사용 가능

2. **연산 자원(시간, 성능)**
   - K가 커질수록 모델을 더 많이 학습시켜야 하므로 시간이 오래 걸림  
   - 리소스가 한정되어 있다면 K=5 정도가 실용적

3. **데이터의 분포**
   - 클래스 비율이 중요한 문제(예: 불균형 데이터)에서는 Stratified K-Fold 사용을 권장  
     → 각 fold에도 동일한 클래스 비율 유지

4. **모델의 복잡도**
   - 복잡한 모델일수록 과적합 가능성이 크므로 K를 크게 설정해 더 안정적인 평가 필요  
   - 예: 딥러닝 모델보다 선형 회귀 모델에서는 K를 작게 설정해도 괜찮음

---

### 📌 일반적으로 많이 쓰는 K 값

| K 값 | 특징 |
|------|------|
| K=3 | 빠른 연산과 적은 자원으로 가능, 낮은 컴퓨팅 파워 |
| K=5 | **가장 보편적**, 연산과 성능 평가 간의 균형 |
| K=10 | 비교적 성능 추정이 안정적, 컴퓨팅 파워가 좋을 때|

---

### ✅ TIP: K를 어떻게 정해야 하나요?

> **데이터 크기**, **모델 복잡도**, **시간/자원**을 모두 고려해 K를 선택해야 하며,  
> 일반적으로는 **5 또는 10**이 권장되는 표준값이다.  
> 모델 성능이 민감하거나 데이터가 적다면 K를 키우고, 속도가 중요하면 K를 줄이면 된다.

---

### ✅ 한 줄 요약

> K는 너무 작으면 불안정하고, 너무 크면 느립니다.  
> **5~10 정도에서 가장 효율적인 균형**을 가질 수 있습니다.

