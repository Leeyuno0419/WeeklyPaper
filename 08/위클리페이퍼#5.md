# 📘 [AI] 위클리페이퍼 #5  
---
> **작성일**: 2025년 8월 11일  
> **작성자**: 이유노  

## 🔹 01. 딥러닝 프레임워크인 PyTorch와 TensorFlow를 비교해보세요.

### 📌 PyTorch vs TensorFlow  

| 구분 | **PyTorch** | **TensorFlow** |
|------|-------------|----------------|
| **개발사** | Meta(구 Facebook) | Google |
| **코드 스타일** | Pythonic한 문법, 직관적이고 디버깅이 쉬움 | 선언형(Graph) 스타일, `tf.function`으로 성능 최적화 가능 |
| **계산 방식** | 동적 계산 그래프(Dynamic Computation Graph) – 실행하면서 그래프 생성 | 정적 계산 그래프(Static Graph) – 사전에 그래프 정의 후 실행 |
| **학습곡선** | Python과 유사해 진입 장벽 낮음 | 초반 러닝 커브 높으나, 배포·서빙에 강점 |
| **디버깅** | 일반 Python 디버거(PDB) 사용 가능 | Graph 실행 환경이라 디버깅 다소 복잡 |
| **생태계** | 연구, 프로토타입 개발에 강점 / TorchVision·TorchText 등 부가 라이브러리 풍부 | 산업 배포, 모바일/임베디드 지원 / TensorFlow Lite, TensorFlow Serving 제공 |
| **속도** | 최근 버전에서 TensorFlow와 유사 | 하드웨어 가속(TPU) 최적화 강점 |

> **정리**  
> - **PyTorch**: 직관적인 문법, 연구/실험/프로토타입에 적합  
> - **TensorFlow**: 배포·서빙, 대규모 산업 환경에 강점  

---

### :thumbsup: PyTorch 장점  
1. Python과 유사한 문법 → 빠른 개발, 디버깅 편리  
2. 동적 그래프 → 데이터 흐름이 직관적  
3. 학계·연구 커뮤니티에서 폭넓게 사용  

### :thumbsdown: PyTorch 단점  
- 산업 배포 시 TensorFlow 대비 최적화된 서빙 툴이 적음  

---

### :thumbsup: TensorFlow 장점  
1. 산업 배포 및 대규모 서비스에 강점  
2. 다양한 플랫폼 지원(TPU, 모바일, 웹)  
3. Keras 통합으로 코드 작성 편리  

### :thumbsdown: TensorFlow 단점  
- 코드 구조가 복잡해 초심자 접근 난이도 높음  

---

## 🔹 02. PyTorch에서 텐서란 무엇이고, NumPy의 Array(배열)과 어떤 차이가 있나요?

### 📌 PyTorch의 Tensor란?  
- **텐서(Tensor)**: 다차원 배열을 표현하는 자료구조  
- 스칼라(0차원), 벡터(1차원), 행렬(2차원)을 확장한 일반화된 형태  
- PyTorch에서 모델의 입력·출력, 가중치 등을 저장하고 연산하는 기본 단위  

---

### 📌 NumPy Array와의 차이  

| 구분 | **PyTorch Tensor** | **NumPy Array** |
|------|-------------------|-----------------|
| **연산 장치** | CPU와 GPU(CUDA) 모두 지원 | CPU 연산만 지원 |
| **자동 미분** | `requires_grad=True` 설정 시 자동으로 연산 기록·미분 가능 | 자동 미분 기능 없음 |
| **연산 속도** | GPU 병렬 연산 가능 → 대규모 연산 빠름 | CPU 연산 속도에 의존 |
| **호환성** | `.numpy()` / `torch.from_numpy()`로 상호 변환 가능 | 변환 시 같은 메모리 참조(얕은 복사) |

---

### 예시 코드  

```python
import torch
import numpy as np

# PyTorch Tensor 생성
t = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32, requires_grad=True)

# NumPy Array 생성
a = np.array([[1, 2], [3, 4]], dtype=np.float32)

# GPU로 이동
t_gpu = t.to('cuda')

# 변환
t_to_numpy = t.detach().numpy()
a_to_tensor = torch.from_numpy(a)
