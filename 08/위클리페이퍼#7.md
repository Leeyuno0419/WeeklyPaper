# 📘 [AI] 위클리페이퍼 \#6
---
> **작성일**: 2025년 8월 25일
>
> **작성자**: 이유노

## 🔹 01. 이미지를 모델에 입력하기 전에 리사이징(Resizing)과 정규화(Normalization)를 하는 이유는 무엇인가요?

### 📌 이미지 전처리: 리사이징 & 정규화

딥러닝 모델이 이미지를 효과적으로 학습하기 위해서는 데이터를 일관된 형태로 만들어주는 전처리(Preprocessing) 과정이 필수적입니다. 그중 리사이징과 정규화는 가장 기본적인 단계입니다.

| 구분 | **리사이징 (Resizing)** | **정규화 (Normalization)** |
| :--- | :--- | :--- |
| **목적** | 모델의 **입력 크기를 통일**하여 일관된 연산을 가능하게 함 | 픽셀 값의 **분포를 조정**하여 학습을 안정적이고 빠르게 만듦 |
| **이유** | 1. **고정된 입력 크기**: 딥러닝 모델은 정해진 크기의 텐서(Tensor)를 입력으로 받음2. **연산 효율성**: 이미지 크기를 줄여 학습에 필요한 메모리와 계산량을 감소시킴 | 1. **빠른 수렴**: 데이터 스케일을 줄여 손실 함수(Loss Function)의 표면을 단순화하고, 경사 하강법(Gradient Descent)이 최적점을 더 빨리 찾도록 도움2. **안정적인 학습**: 특정 가중치에 편향되는 것을 방지하여 학습 안정성을 높임 |
| **방법** | `(너비, 높이)`를 특정 크기(예: 224x224)로 강제 변환 | 픽셀 값을 특정 범위(예: 0\~1)로 스케일링. 주로 `(픽셀값 - 평균) / 표준편차` 공식을 사용 |

> **정리** 💡
>
>   - **리사이징**: 모델이 이미지를 '받을 수 있도록' 크기를 맞추는 작업
>   - **정규화**: 모델이 이미지를 '잘 학습할 수 있도록' 값의 분포를 바꿔주는 작업

-----

## 🔹 02. 데이터 증강(Data Augmentation)이란 무엇이며, 이미지 데이터에서 주로 사용하는 증강 기법에는 어떤 것들이 있나요?

### 📌 데이터 증강 (Data Augmentation)이란?

**데이터 증강**은 보유한 학습 데이터셋을 인위적으로 변형하고 확장하여 **데이터의 양과 다양성을 늘리는 기술**입니다. 적은 양의 데이터로도 모델이 다양한 상황을 학습하게 하여, 특정 데이터에만 과적합(Overfitting)되는 것을 방지하고 일반화 성능을 높이는 효과가 있습니다.

### 📌 주요 이미지 증강 기법

| 기법 | 설명 |
| :--- | :--- |
| 🖼️ **기하학적 변환 (Geometric Transformations)** | |
| **좌우/상하 반전 (Flip)** | 이미지를 수평 또는 수직으로 뒤집습니다. |
| **회전 (Rotation)** | 이미지를 특정 각도(예: 15도, 30도)로 회전시킵니다. |
| **크기 조절 (Scale)** | 이미지를 확대하거나 축소합니다. |
| **자르기 (Crop)** | 이미지의 일부를 무작위로 잘라냅니다. |
| **이동 (Shift)** | 이미지를 상하좌우로 약간씩 이동시킵니다. |
| 🎨 **색상 변환 (Color Space Transformations)** | |
| **밝기/대비 조절 (Brightness/Contrast)** | 이미지의 밝기나 대비를 변경하여 조명이 다른 환경을 흉내 냅니다. |
| **채도/색조 변경 (Saturation/Hue)** | 이미지의 색상 톤을 조절합니다. |
| 🔪 **기타 기법** | |
| **노이즈 추가 (Noise Injection)** | 이미지에 가우시안 노이즈 등을 추가하여 약간의 왜곡을 줍니다. |
| **컷아웃 (Cutout) / 랜덤 이레이징 (Random Erasing)** | 이미지의 일부 영역을 무작위로 지워(가려), 모델이 특정 부분에만 의존하지 않도록 합니다. |

-----

## 🔹 03. Transfer Learning(전이 학습)이란 무엇이며, 이미지 분류 모델에서 어떻게 활용할 수 있나요?

### 📌 전이 학습 (Transfer Learning)이란?

**전이 학습**은 **하나의 문제 해결을 위해 학습된 모델의 지식(가중치)을 다른 관련 문제에 재사용하는 기법**입니다. 특히 대규모 데이터셋(예: ImageNet)으로 미리 학습된 모델(Pre-trained Model)을 가져와, 우리가 해결하려는 특정 작업(예: 특정 종류의 꽃 분류)에 맞게 조정하여 사용하는 방식이 널리 쓰입니다.

> **핵심 아이디어** 🧠
> "바퀴를 처음부터 다시 발명하지 말자." 이미 잘 만들어진 지식을 가져와 내 문제에 적용하는 것과 같습니다.

### 📌 이미지 분류 모델에서의 활용법

대규모 이미지 데이터로 사전 학습된 모델(예: ResNet, VGG, EfficientNet)은 이미지의 기본적인 특징(선, 질감, 패턴 등)을 추출하는 능력이 매우 뛰어납니다. 이 능력을 활용하는 방법은 크게 두 가지입니다.

1.  **특징 추출 (Feature Extraction)**

      - **방법**: 사전 학습된 모델의 일부(주로 앞부분의 합성곱층)는 그대로 두고, 맨 끝의 분류기(Classifier) 부분만 우리의 목적에 맞는 새로운 분류기로 교체합니다. 이때 사전 학습된 부분의 가중치는 변경되지 않도록 \*\*'동결(Freeze)'\*\*합니다.
      - **언제 사용?**: 보유한 데이터셋이 작고, 사전 학습된 데이터셋과 유사할 때 효과적입니다. 학습 속도가 매우 빠릅니다.
      - `[사전 학습 모델 (가중치 동결)] -> [새로운 분류기 (학습 대상)]`

2.  **미세 조정 (Fine-Tuning)**

      - **방법**: 특징 추출과 동일하게 모델을 구성하되, 사전 학습된 모델의 일부(주로 뒷부분의 고차원 특징 추출 레이어)까지 \*\*'동결을 해제(Unfreeze)'\*\*하여 우리의 데이터셋으로 조금 더 학습시킵니다.
      - **언제 사용?**: 보유한 데이터셋이 어느 정도 크고, 더 높은 성능을 원할 때 사용합니다. 사전 학습된 지식을 우리 문제에 더 적합하게 맞출 수 있습니다.
      - `[사전 학습 모델 (일부 동결 해제 및 학습)] -> [새로운 분류기 (학습 대상)]`

> **기대 효과** 👍
>
>   - **더 적은 데이터**: 수백만 장의 이미지가 없어도 높은 성능을 달성할 수 있습니다.
>   - **더 빠른 학습**: 처음부터 학습하는 것보다 훨씬 빠르게 모델이 수렴합니다.
>   - **더 높은 성능**: 검증된 아키텍처와 가중치를 사용하므로 성능이 뛰어납니다.
